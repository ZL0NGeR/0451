# Импортируем библиотеки

import pandas as pd
import numpy as np
from numpy.random import seed
from numpy.random import randn
from scipy.stats import mannwhitneyu
from scipy.stats import norm
from tqdm.auto import tqdm
import matplotlib.pyplot as plt
plt.style.use('ggplot')
%config IPCompleter.greedy = True

# Читаем файл с выборкой

df = pd.read_csv('https://stepik.org/media/attachments/lesson/389496/hw_bootstrap.csv', sep=';')
df.head()

# Приводим данные к правильному виду для Питончика(float)

Treatment = pd.to_numeric(df[df.experimentVariant == 'Treatment'].value.str.replace(',', '.'))
Control = pd.to_numeric(df[df.experimentVariant == 'Control'].value.str.replace(',', '.'))

def get_bootstrap(
    data_column_1, # Числовые значения первой выборки
    data_column_2, # Числовые значения второй выборки
    boot_it = 1000, # Количество бутстрэп-подвыборок
    statistic = np.mean, # Интересующая нас статистика
    bootstrap_conf_level = 0.95 # Уровень значимости
):
    boot_len = max([len(data_column_1), len(data_column_2)])
    boot_data = []
    for i in tqdm(range(boot_it)): # Извлекаем подвыборки
        samples_1 = data_column_1.sample(
            boot_len, 
            replace = True # Параметр возвращения
        ).values
        
        samples_2 = data_column_2.sample(
            boot_len, # Чтобы сохранить дисперсию, берем такой же размер выборки
            replace = True
        ).values
        
        boot_data.append(statistic(samples_1-samples_2)) 
    pd_boot_data = pd.DataFrame(boot_data)
        
    left_quant = (1 - bootstrap_conf_level)/2
    right_quant = 1 - (1 - bootstrap_conf_level) / 2
    quants = pd_boot_data.quantile([left_quant, right_quant])
        
    p_1 = norm.cdf(
        x = 0, 
        loc = np.mean(boot_data), 
        scale = np.std(boot_data)
    )
    p_2 = norm.cdf(
        x = 0, 
        loc = -np.mean(boot_data), 
        scale = np.std(boot_data)
    )
    p_value = min(p_1, p_2) * 2
        
    # Визуализация
    _, _, bars = plt.hist(pd_boot_data[0], bins = 50)
    for bar in bars:
        if abs(bar.get_x()) <= quants.iloc[0][0] or abs(bar.get_x()) >= quants.iloc[1][0]:
            bar.set_facecolor('red')
        else: 
            bar.set_facecolor('grey')
            bar.set_edgecolor('black')
    
    plt.style.use('ggplot')
    plt.vlines(quants,ymin=0,ymax=50,linestyle='--')
    plt.xlabel('boot_data')
    plt.ylabel('frequency')
    plt.title("Histogram of boot_data")
    plt.show()
       
    return {"boot_data": boot_data, 
            "quants": quants, 
            "p_value": p_value}
            
# Будем пробовать бутстрап на эксп. распределении
np.random.seed(5)      

booted_data = get_bootstrap(Treatment, Control) # В результате хранится разница двух распределений, ДИ и pvalue

booted_data["quants"] # ДИ

# p_value Бутстрепа

booted_data["p_value"] # Альфа

# p_value U-критерия Манна-Уитни

stat, p = mannwhitneyu(Treatment, Control)
print('Statistics=%.3f, p=%.3f' % (stat, p))

# Итог: в бутстрепе для проверки уровня значимости мы установили значение 0.95. 
# Это значит что если А будет отличаться от В более чем на 0.95, то это будет говороить о том что у нас есть значимые различия. 
# А в критерии Манна-Уитни мы отклоняем нулевую гепотезу, тк если если она верна, то вероятность получить такие или еще более значимые различия 
# меньше 0.05 Вывод: оба теста говорят о статистически значимых различиях в тесте и контроле.
